::: {.content-hidden}
$
{{< include macros.tex >}}
$
:::




# Curvature and Torsion

We have seen how to describe curves and reparametrized them. Now we want to look at local properties of curves:

- How much does a curve twist?
- How much does a curve bend?

We will measure two quantities:

- **Curvature**: measures how much a curve $\g$ deviates from a straight line.
- **Torsion**: measures how much a curve $\g$ fails to lie on a plane.

For example a 2D spiral is curved, but still lies in a plane. Instead the Helix both deviates from a straight line and *pulls away* from any fixed plane. 



## Curvature 

We start with an informal discussion. Suppose $\g$ is a straight line
$$
\g(t) = \mathbf{a} + t \mathbf{v}
$$
with $\mathbf{a}, \mathbf{v} \in \R^3$. The tangent vector to $\g$ is constant
$$
\dot\g(t) =  \mathbf{v} \,.
$$
Whatever the definition of curvature will be, it has to hold that $\g$ has zero curvature in this case. If we further derive the tangent vector, we obtain
$$
\ddot\g(t) =  0 \,.
$$
Thus $\ddot \g$ seems to be a good candidate for the definition of curvature of $\g$ at the point $\g(t)$.  


Suppose now that $\g$ is a curve in $\R^2$ with unit speed. We have proven that in this case
$$
\dot \g \cdot \ddot\g = 0 \,,
$$
that is, the vector $\ddot \g$ is orthogonal to the tangent $\dot \g$ at all times. Now let $\mathbf{n}(t)$ be the unit vector orthogonal to $\dot \g(t)$ at the point $\g(t)$. The amount that the curve $\g$ deviates from its tangent at $\g(t)$ after time $t_0$ is
$$
( \g(t + t_0) - \g(t) ) \cdot \mathbf{n}(t) \,,
$$ {#eq-curvature-heuristics}
as seen in the figure below.


![Amount that $\g$ deviates from tangent is $(\g(t+t_0)-\g(t)) \cdot \nn(t)$](/images/curvature.png){width=70%}


Equation (@eq-curvature-heuristics) is what we take as measure of curvature. Since 
$$
\dot \g(t) \cdot \ddot \g(t) = 0 \quad \mbox{ and } \quad   \dot \g(t) \cdot \mathbf{n}(t)= 0 \,,
$$
we conclude that $\ddot \g(t)$ is parallel to $\mathbf{n}(t)$. Since $\mathbf{n}(t)$ is a unit vector, there exists a scalar $\kappa(t)$ such that 
$$
\ddot \g(t)  = \kappa(t) \, \mathbf{n}(t) \,.
$$
Note that, since $\nn$ is unitary, we have
$$
\kappa(t) = \norm{ \ddot \g(t) }
$$


Now, approximate $\g$ at $t$ with its second order Taylor polynomial:
$$
\g(t+t_0) = \g(t) + \dot\g(t) t_0 + \frac{\ddot\g(t)}{2} t_0^2 + o(t_0)
$$
with the remainder $o(t_0)$ is such that 
$$
\lim_{t_0 \to 0} \ \frac{o(t_0)}{t_0^2} = 0 \,.
$$
Therefore, forgetting about the remainder, 
$$
\g(t+t_0) - \g(t) \approx \dot\g(t) t_0 + \frac{\ddot\g(t)}{2} t_0^2 \,.
$$
Multiplying by $\nn(t)$ we get
$$
(\g(t+t_0) - \g(t)) \cdot \nn(t) \approx \dot\g(t) \cdot \nn(t) t_0 + 
\frac{\ddot\g(t) \cdot \nn(t) }{2} t_0^2\,.
$$
Recalling that 
$$
\dot\g(t) \cdot \nn(t) = 0\,, \quad  \ddot\g(t) \cdot \nn(t) = \kappa(t) \,, 
$$
we then obtain
$$
(\g(t+t_0) - \g(t)) \cdot \nn(t) \approx 
\frac{1}{2} \, \kappa(t) \, t_0^2
$$


::: Important

The amount that $\g$ deviates from a straight line is proportional to 
$$
\kappa(t) = \norm{\ddot \g (t)}\,.
$$

:::

We take this as definition of curvature for a general unit speed curve in $\R^n.$


::: Definition 

Let $\g \ \colon (a,b) \to \R^n$ be a unit speed curve. The **curvature** of $\g$ at $\g(t)$ is
$$
\kappa(t) := \norm{\ddot \g (t)} \,.
$$

:::



Note that $\kappa(t)$ is a function of time. Therefore the curvature of $\g$ can change from point to point.


::: Example

Consider the circle of radius $R>0$:
$$
\g(t) = (R\cos(t),R\sin(t)) \,, \quad t \in [0,2\pi] \,.
$$
To compute the curvature of $\g$ we need to find a unit speed reparametrization. We have shown that:
$$
\g \, \mbox{ regular } \,\,\, \implies \,\,\, \f = s^{-1} \, \mbox{ unit speed reparametrization}
$$
where $s$ is the arc length of $\g$:
$$
s(t):= \int_{t_0}^t \norm{\dot \g(\tau)} \, d\tau  \,.
$$
In our case 
$$
\dot \g(t) = (-R\sin(t), R\cos(t))  \quad \implies \quad 
\norm{\dot \g(t)} = R  
$$
and so $\g$ is regular. The arc length starting at $t_0 = 0$ is
$$
s(t) = \int_{0}^t R d \tau = t R \,.
$$
The inverse of $s$ is
$$
\f(t) := s^{-1} (t) = \frac{t}{R} \,.
$$
Therefore a unit speed reparametrization of $\g$ is 
$$
\tg :=\g \circ \f 
$$
which reads
$$
\tg(t) :=  \left( R \cos \left( \frac{t}{R} \right) , R \sin \left( \frac{t}{R} \right)\right) \,.
$$
We have
\begin{align}
\dot{\tg} (t) & =  \left( - \sin \left( \frac{t}{R} \right) ,  \cos \left( \frac{t}{R} \right)\right) \\
\ddot{\tg} (t) & =  \left( -\frac{1}{R} \cos \left( \frac{t}{R} \right) ,  - \frac{1}{R} \sin \left( \frac{t}{R} \right)\right)
\end{align}
Therefore the curvature of $\g$ is
$$
\kappa(t) = \norm{ \ddot{\tg} (t) } = \frac{1}{R} \,.
$$
In this case $\kappa(t)$ is constant. The curvature also tells us that the smaller the circle, the higher the curvature. For a large circle, like the Earth, the curvature is barely noticeable. 
:::



The curvature is defined for unit speed curves. To circumvent this, in the above example we computed a unit length reparametrization of the circle, and then computed the curvature of the reparametrization.  
If $\g$ is a regular curve, then one could do the same: first compute unit speed reparametrization $\tg$, and from this compute the curvature. When $\g$ is regular and has values in $\R^3$, there is a way to compute $\kappa$ without reparametrizing. To do this, we will need the notion of **cross product**, or **vector product** .

![Procedure for computing curvature $\kappa$](/images/curvature_shortcut.png){width=70%}






## Vector product in $\R^3$


The discussion in this section follows [@do-carmo]. We start by defining **orientation** for a vector space.


::: Definition
### Same orientation

Consider two ordered basis of $\R^3$
$$
b = (b_1,b_2,b_3) \,, \quad \tilde{b} = (\tilde{b}_1,\tilde{b}_2,\tilde{b}_3) \,.
$$
We say that $b$ and $\tilde{b}$ have the same orientation if the matrix of change of basis has positive determinant.

:::

When two basis $b$ and $\tilde{b}$ have the same orientation, we write
$$
b \sim \tilde{b} \,.
$$
The above is clearly an equivalence relation on the set of ordered basis. Therefore the set of ordered basis of $\R^3$ can be decomposed into equivalence classes.
Since the determinant of the matrix of change of basis can only be positive or negative, there are only two equivalence classes.


::: Definition 
### Orientation

The two equivalence classes determined by $\sim$ on the set of ordered basis are called **orientations**. 

:::



::: Definition 
### Positive orientation

Consider the standard basis of $\R^3$ 
$$
e = (e_1,e_2,e_3)
$$
where we set
$$
e_1 = (1,0,0)\,, \quad e_2 = (0,1,0) \,, \quad e_3 = (0,0,1) \,.
$$
Then:

- The orientation corresponding to $e$ is called **positive orientation** of $\R^3$.
- The orientation corresponding to the other equivalence class is called **negative orientation** of $\R^3$.


For a basis $b$ of $\R^3$ we say that:

- $b$ is a **positive basis** if it belongs to the class of $e$.
- $b$ is a **negative basis** if it does not belong to the class of $e$.
:::



::: Example

Since we are dealing with ordered basis, the order in which vectors appear is fundamental. For example, we defined the equivalence class of
$$
e = (e_1,e_2,e_3) \,,
$$
to be the positive orientation of $\R^3$. In particular $e$ is a positive basis.  
Consider instead
$$
\tilde{e} = (e_2,e_1,e_3) \,.
$$
The matrix of change of variables between $\tilde{e}$ and $e$ is 
$$
(e_2 | e_1 | e_3 ) = \left(
\begin{array}{ccc}
0 & 1 & 0 \\ 
1 & 0 & 0 \\
0 & 0 & 1 \\
\end{array}
\right)
$$
and the latter has negative determinant. Thus $\tilde{e}$ does not belong to the class of $e$, and is therefore a negative basis. 
:::


We are now ready to define the vector product in $\R^3$.


::: Definition
### Vector product in $\R^3$   

Let $u,v \in \R^3$. The vector product of $u$ and $v$ is the unique vector 
$$
u \times v \in \R^3
$$
which satisfies the property:
$$
(u \times v) \cdot w = 
\left|
\begin{array}{ccc}
u_1 & u_2 & u_3 \\
v_1 & v_2 & v_3 \\
w_1 & w_2 & w_3 \\
\end{array}
\right| \,, \quad \forall \, w \in \R^3 \,.
$${#eq-def-vector-product}
Here $|a_{ij}|$ denotes the determinant of the matrix $(a_{ij})$, and 
$$
u= \sum_{i=1}^3 u_i e_i \,, \quad
v= \sum_{i=1}^3 v_i e_i \,, \quad
w= \sum_{i=1}^3 w_i e_i \,,
$$
with $(e_1,e_2,e_3)$ standard basis of $\R^3$.
:::


The following proposition gives an explicit formula for computing $u \times v$.


::: Proposition

Let $u,v \in \R^3$. Then
$$
u \times v = 
\left|
\begin{array}{cc}
u_2 & u_3  \\
v_2 & v_3 
\end{array}
\right| e_1 -
\left|
\begin{array}{cc}
u_1 & u_3  \\
v_1 & v_3 
\end{array}
\right| e_2 +
\left|
\begin{array}{cc}
u_1 & u_2  \\
v_1 & v_2 
\end{array}
\right| e_3  \,. 
$$ 
:::


::: Proof
Denote by $(u \times v)_i$ the $i$-th component of $u \times v$ with respect to the standard basis, that is,
$$
u \times v = \sum_{i=1}^3  (u \times v)_i \, e_i \,.
$$
We can use (@eq-def-vector-product) with $w = e_1$ to obtain 
$$
(u \times v) \cdot e_1  = 
\left|
\begin{array}{ccc}
u_1 & u_2 & u_3 \\
v_1 & v_2 & v_3 \\
 1  & 0   &   0 \\
\end{array}
\right| =
\left|
\begin{array}{cc}
u_2 & u_3  \\
v_2 & v_3 
\end{array}
\right|
$$
where we used the Laplace expansion for computing the determinant of the $3 \times 3$ matrix. As the standard basis is orthonormal, by bilinearity of the scalar product we get
$$
(u \times v) \cdot e_1 = \sum_{i=1}^3  (u \times v)_i \, e_i \cdot e_1 = (u \times v)_i \,.
$$
Therefore we have shown
$$
(u \times v)_1 = \left|
\begin{array}{cc}
u_2 & u_3  \\
v_2 & v_3 
\end{array}
\right| \,.
$$
Similarly we obtain
$$
(u \times v)_2  = \left|
\begin{array}{ccc}
u_1 & u_2 & u_3 \\
v_1 & v_2 & v_3 \\
 0  & 1   &   0 \\
\end{array}
\right| = -
\left|
\begin{array}{cc}
u_1 & u_3  \\
v_1 & v_3 
\end{array}
\right|
$$
and 
$$
(u \times v)_3  = \left|
\begin{array}{ccc}
u_1 & u_2 & u_3 \\
v_1 & v_2 & v_3 \\
 0  & 0   &   1 \\
\end{array}
\right| = 
\left|
\begin{array}{cc}
u_1 & u_2  \\
v_1 & v_2 
\end{array}
\right| \,,
$$
from which we conclude.
:::



::: {.Proposition #proposition-vector-product}

The vector product in $\R^3$ satisfies the following properties: For all $u, v \in \R^3$ 

1. $u \times v = - v \times u$
2. $u \times v = 0$ if and only if $u$ and $v$ are linearly dependent
3. $(u \times v) \cdot u = 0$, $(u \times v) \cdot v = 0$
4. Moreover for all $w \in \R^3$, $a,b \in \R$
$$
(au + bw) \times v = a u \times v + bw \times w 
$$

:::

The proof, which is based on the properties of determinants, is omitted.


::: Remark
### Geometric interpretation of vector product

Let $u, v \in \R^3$ be linearly independent. We make some observations:

- Property 3 in Proposition \ref{proposition-vector-product} says that
$$
(u \times v) \cdot u = 0 \,, \quad  (u \times v) \cdot v = 0 \,.
$$
Therefore $u \times v$ is orthogonal to both $u$ and $v$. 

- In particular $u \times v$ is orthogonal to the plane generated by $u$ and $v$.

- Since $u$ and $v$ are linearly independent, Property 2 in Proposition \ref{proposition-vector-product} says that
$$
u \times v \neq 0
$$

- Therefore we have
$$
(u \times v) \cdot (u \times v) = | u \times v |^2 > 0 
$$

- On the other hand, using the definition of $u \times v$ with $w = v \times w$ yields
$$
(u \times v) \cdot (u \times v) =
\left|
\begin{array}{ccc}
u_1 & u_2 & u_3 \\
v_1 & v_2 & v_3 \\
(u \times v)_1 & (u \times v)_2 & (u \times v)_3 \\
\end{array}
\right| 
$$

- Therefore the determinant of the matrix
$$
(u | v | u \times v)
$$
is positive. This shows that 
$$
(u , v , u \times v)
$$
is a **positive basis** of $\R^3$.

- For all $u,v,x,y \in \R^3$ it holds
$$
(u \times v) \cdot (x \times y ) = 
\left|
\begin{array}{cc}
u \cdot x & v \cdot x  \\
u \cdot y & v \cdot y 
\end{array}
\right| \,.
$${#eq-formula-cross}
Indeed, one can check that the above formula holds for the standard vectors $e_i$, and thus the general formula follows by linearity.

- Using (@eq-formula-cross) we get
\begin{align}
|u \times v|^2 & = (u \times v) \cdot (u \times v) = 
\left|
\begin{array}{cc}
u \cdot u & v \cdot u  \\
u \cdot v & v \cdot v 
\end{array}
\right|   \\
& = |u|^2|v|^2 - |u \cdot v|^2 \\
& = |u|^2|v|^2 - |u|^2 |v|^2 \cos^2(\theta) \\
& = |u|^2|v|^2 (1-\cos^2(\theta)) \\
& = |u|^2|v|^2 \sin^2(\theta) \\
& = A^2  
\end{align} 
where $A$ is the area of the parallelogram with sides $u$ and $v$.
:::


![For $u,v$ linearly independent, $u \times v$ is orthogonal to the plane generated by $u,v$. Moreover $|u \times v|$ is the area of the parallelogram with sides $u,v$, and $(u,v,u \times v)$ is a positive basis of $\R^3$](/images/vector_product_orthogonal.png){width=70%}


We conclude with a summary of the above remark.

::: Remark
### Summary: Properties of $u \times v$

Let $u,v \in \R^3$ be linearly independent. Then

- $u \times v$ is orthogonal to the plane spanned by $u,v$
- $|u \times v|$ is equal to the area of the parallelogram with sides $u,v$
- $u \times v$ is such that
$$
(u,v,u\times v)
$$
is a positive basis of $\R^3$.

:::






## Curvature formula in $\R^3$


Given a unit speed curve
$$
\g \ \colon (a,b) \to \R^n
$$
we defined its curvature as
$$
\kappa(t) = \norm{ \ddot{\g}(t) } \,.
$$
If $\g$ is not unit speed then the curvature is not defined. However, when $\g$ is regular, then we can find a unit-speed reparametrization $\tg$ of $\g$, and compute $\kappa$ as
$$
\kappa(t) = \norm{ \ddot{\tg}(t) } \,.
$$
If $\g$ is a regular curve in $\R^3$, there is a way to compute $\kappa$ without passing through $\tg$. The formula for computing $\kappa$ is as follows. 

::: Proposition

Let $\g \colon (a,b) \to \R^3$ be a regular curve. Then the curvature $\kappa(t)$ of $\g$ at $\g(t)$ is given by
$$
\kappa(t) = \frac{ \norm{\ddot \g \times \dot \g} }{ \norm{\dot \g}^3 } \,. 
$${#eq-curvature}

:::


We delay the proof of the above Proposition, as this will get easier when the **Frenet frame** is introduced. For a proof which does not make use of the Frenet frame, see the proof of Proposition 2.1.2 in [@pressley].

For now we use (@eq-curvature) the above proposition to compute the curvature on specific curves.

::: Example

Consider the Helix
$$
\g (t) = ( \cos(t) , \sin(t) , t) \,, \quad t \in \R \,.
$$

:::




## Signed curvature of plane curves

The signed curvature is the rate at which the tangent vector $\dot \g$ of the curve $\g$ rotates. The signed curvature is:

- positive if $\dot \g$ is rotating anticlockwise
- negative if $\dot \g$ is rotating clockwise

A rigorous justification of the above statement is found in Proposition 2.2.3 in [@pressley].





We do not prove the above theorem. For a proof, see Theorem 2.2.6 in [@pressley].